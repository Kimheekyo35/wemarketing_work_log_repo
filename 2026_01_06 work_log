# 2026_01_06 work_log

🔥 금일 목표
- 로그인이 필요한 게시글을 크롤링하여 구글 스프레드 시트에 자동으로 저장되게 코드 작성

🚦 업무 순서
1. 로그인할 수 있게 쿠키 구성
2. 로그인을 입력한 crawler가 크롤링하여 시트에 자동 저장까지

🚨 문제점
1. 쿠키로 접근을 빈번하게 접근하여 로딩창에서 멈추는 상황 발생
2. 스프레드시트의 경우, 호출할 수 있는 횟수가 정해져있음
3. 로그가 호출할 때마다 초기화되고, 불필요한 로그가 많이 포함됨 -> 기존에 로그 작성이 "w" 였는데, "a"로 바꿈 / log 파일에 필요한 log들만 log_step으로 묶어줌. 나머지는 print

💫✏️📌
처음에는 쿠키가 적용된 크롤러로 모든 url을 접근했음. 하지만 문제점이 발생한 후에는, trash_url이라는 빈 리스트를 만들고
쿠키가 적용되지 않은 crawler가 시트에 존재하는 url을 접근하게 구성했음.
이후에, trash_url은 cookie_login() 함수가 적용된 cookie_crawler가 url에 접근하여 정보를 파싱해오게 구성했음.

또한, 처음 trash_url에 있는 url들을 접근할 떄마다 스프레드시트도 같이 호출했음. 하지만 list 전체를 한번에 접근할 수 있도록 구성한 이후에는, 최초  1번만 스프레드시트 API를 호출함
